---
title: "Civic opportunity measurement"
author: "Jae Yeon Kim"
date: "`r Sys.Date()`"
output: html_document
---

# Import pkgs 

```{r}
if (!require(pacman)) install.packages("pacman")

pacman::p_load(
  tidyverse,
  glue,
  here,
  purrr,
  estimatr,
  effectsize,
  ggrepel,
  patchwork,
  corrplot,
  corrr,
  tidycensus,
  callr,
  vroom,
  naniar,
  modelsummary,
  gt,
  DT,
  # ltm # point-biserial correlation
  sf,
  tigris,
  tmap,
  RColorBrewer,
  usdata
)

devtools::install_github("graemeblair/stdidx")
library(stdidx)

options(es.use_symbols = TRUE) # get nice symbols

custom_theme <- function(size = 13) {
  theme_bw(base_size = size) +
    theme(
      aspect.ratio = 1.2,
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      axis.text.x = element_text(margin = margin(t = 6)),
      plot.title = element_text(size = 12),
      plot.subtitle = element_text(size = 10),
      plot.caption = element_text(colour = "grey50", hjust = 0),
      legend.position = "bottom"
    )
}

ggplot2::theme_set(custom_theme())
```

# Import data (from local sources)

```{r}
# this is the main data
mbf <- vroom(here("raw_data", "irs_mbf.csv"))

# org activities from the websites and elsewhere
org_activities <- vroom(here("raw_data", "irs_org_activities.csv"))

irs_activities <- vroom(here("raw_data", "irs_nonweb_activities.csv"))

irs_activities <- irs_activities %>%
  replace_na(list(volunteer_text = 0, member_text = 0)) # without this, the following mutate won't work

# FIPS (county-level)
fips <- read_csv(here("raw_data", "fips_with_population.csv"), col_types = (ZCTA <- "c"))

# FIPS-level other census details
fips_census_agg <- read_csv(here("raw_data", "census_fips_aggregate.csv"))

# social capital data (county-level)
social_capital <- read_csv(here("raw_data", "social_capital.csv"))

# PO BOX status
po_status <- read_csv(here("raw_data", "irs_po_status.csv"))
```

```{r}
# other demographic data
census_detail <- read_csv(here("raw_data", "census_zcta_detail_data.csv"), col_types = (GEOID <- "c"))

zcta_fips <- read_csv(here("raw_data", "zcta_cnts.csv"))

census_subject <- read_csv(here("raw_data", "census_zcta_subject_data.csv"), col_types = (GEOID <- "c"))

county_class <- read_csv(here("raw_data", "County_Classifications.csv"))

# county_mutual <- read_csv(here("raw_data", "reproduction_data_mutual_aid_hubs_county.csv"))

names(county_class)[1] <- "FIPS"
```

# Create a sampling frame

```{r}
org_activities_combined <- irs_activities %>%
  left_join(org_activities) %>%
  mutate(
    volunteer = ifelse(volunteer_text == 1, 1, volunteer),
    membership = ifelse(member_text == 1, 1, membership)
  )
```

```{r}
org_activities_mbf <- org_activities_combined %>%
  left_join(mbf %>% dplyr::select(ein, state, city, zip, irs_group)) %>%
  mutate(grouping_value = if_else(irs_group != "0000", irs_group, ein)) %>%
  left_join(po_status)

nrow(org_activities_mbf) # 1,774,798, approximately 1.8M orgs this is the sampling frame
```

```{r}
org_activities_mbf <- org_activities_mbf %>%
  # We call website but actually this variable indicates an org whose activity could be extracted either via its website or IRS report (for volunteer and membership variables)
  mutate(website = ifelse(!is.na(take_action) | !is.na(volunteer) | !is.na(membership) | !is.na(events) | !is.na(resources) | !is.na(advocacy) | !is.na(services) | !is.na(chapters) | !is.na(board) | !is.na(press) | !is.na(donations), 1, 0)) %>%
  dplyr::select(ein, state, city, zip, take_action, volunteer, membership, events, website, grouping_value, is_po)
```


```{r}
org_activities_mbf$website %>% sum() # 894,888

org_activities_mbf <- org_activities_mbf %>%
  filter(website == 1) %>% # this includes both websites and IRS
  filter(is_po != 1) # PO BOX

nrow(org_activities_mbf) # 682,985

org_activities_mbf <- org_activities_mbf %>%
  replace_na(list(take_action = 0, volunteer = 0, membership = 0, events = 0))

# the first 5 digits
org_activities_mbf$ZCTA <- substr(org_activities_mbf$zip, 1, 5)
```

```{r}
nonweb_eins <- irs_activities %>%
  rename(
    volunteer = volunteer_text,
    membership = member_text
  ) %>%
  select(ein, volunteer, membership) %>%
  # replace_na(list(volunteer = 0, membership = 0)) %>%
  filter(volunteer == 1 | membership == 1) %>%
  pull(ein)

org_activities_mbf$nonweb <- org_activities_mbf$ein %in% nonweb_eins

org_activities_mbf %>%
  mutate(web = ifelse(nonweb == FALSE | nonweb == TRUE & take_action == 1 | nonweb == TRUE & events == 1, TRUE, FALSE)) %>%
  mutate(status = as.numeric(nonweb) + as.numeric(web)) %>%
  mutate(status = ifelse(status == 2, "Both",
    ifelse(status == 1 & web == TRUE, "Web",
      ifelse(status == 1 & nonweb == TRUE, "IRS", NA)
    )
  )) %>%
  group_by(status) %>%
  summarize(n = n()) %>%
  mutate(freq = n / sum(n))
```

# Construct validity test at the org level

* The following three measures are on a 0-1 scale. 

* The objective of this exercise is to test the construct validity. This refers to the extent to which the instrument measures what it claims to measure in theory.

```{r}
org_activities_mbf <- org_activities_mbf %>%
  mutate(opp_binary = ifelse(volunteer == 1 | membership == 1 | take_action == 1 | events == 1, 1, 0)) %>%
  mutate(
    opp_mean = idx_mean(volunteer, membership, take_action, events), # mean
    opp_invcov = idx_invcov(volunteer, membership, take_action, events) # inverse covariance matrix
  )

prin_out <- princomp(~ volunteer + membership + take_action + events, data = org_activities_mbf)

org_activities_mbf$opp_princomp <- prin_out$scores[, 1] # the first factor

write_csv(org_activities_mbf, here("processed_data", "org_measures.csv"))
```

```{r}
unit_cor_df <- org_activities_mbf %>%
  dplyr::select(take_action, volunteer, membership, events, opp_binary, opp_mean, opp_invcov, opp_princomp) %>%
  rename(
    "Taking action" = take_action,
    "Volunteering" = volunteer,
    "Membership" = membership,
    "Holding events" = events,
    "Binary index" = opp_binary,
    "Mean index" = opp_mean,
    "Inverse covariance matrix index" = opp_invcov,
    "Principal component first factor index" = opp_princomp
  ) %>%
  correlate() %>%
  focus(c(
    "Binary index",
    "Mean index",
    "Inverse covariance matrix index",
    "Principal component first factor index"
  ))

unit_cor_df
```

```{r}
sd(unit_cor_df[, 2] %>% unlist()) # sd binary index
sd(unit_cor_df[, 3] %>% unlist()) # sd mean index
sd(unit_cor_df[, 4] %>% unlist()) # sd inverse covariance matrix index
sd(unit_cor_df[, 5] %>% unlist()) # sd principal component first factor index
```

```{r}
con_plot <- unit_cor_df %>%
  pivot_longer(matches("index")) %>%
  ggplot(aes(
    x = term, y = name,
    fill = value,
    label = round(value, 2)
  )) +
  geom_tile() +
  labs(
    x = "",
    y = "",
    fill = "Correlation coefficients",
    label = "Correlation coefficients"
  ) +
  scale_fill_gradient2(
    low = "white",
    high = "green",
    midpoint = 0.4,
    limit = c(0, 1),
    space = "Lab"
  ) +
  # guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
  geom_label(
    col = "black",
    show.legend = FALSE
  ) +
  # coord_flip() +
  # ylim(c(0,1)) +
  theme(legend.position = "right") +
  scale_x_discrete(guide = guide_axis(n.dodge = 2))
```

```{r}
con_plot

ggsave(here("outputs", "con_plot.png"))
```

# Link org and census data at the county level

```{r}
# county classification
county_class <- county_class %>%
  mutate(urban_suburban_rural = case_when(
    RuralUrbanContinuumCode2013 %in% c(1, 2, 3) ~ "Urban",
    RuralUrbanContinuumCode2013 %in% c(4, 5, 6) ~ "Suburban",
    RuralUrbanContinuumCode2013 %in% c(7, 8, 9) ~ "Rural",
    is.na(RuralUrbanContinuumCode2013) ~ NA
  )) %>%
  mutate(urban_suburban_rural = factor(urban_suburban_rural, levels = c("Urban", "Suburban", "Rural", NA)))
```

```{r}
# census_api_key(key = "69df6af664132347b84276a365ce76d4c16cf336")

# var20 <- load_variables(2020, "acs5", cache = TRUE)

# get_acs_zcta <- function(zcta_vec) {
#   census_api_data <- get_acs(
#     geography = "zcta",
#     variables = c(
#       "B05002_001", # total #
#       "B05002_013"
#     ), # foreign born #
#     geometry = FALSE,
#     output = "wide",
#     zcta = zcta_vec,
#     year = 2020
#   )
# }

# census_api_data <- map_dfr(census$ZCTA, get_acs_zcta)

# write_csv(census_api_data, here("raw_data", "census_api_data.csv"))

# census_api_data <- read_csv(here("raw_data", "census_api_data.csv"))

# census_foreign <- census_api_data %>%
# mutate(foreign_born_pct = B05002_013E / B05002_001E) %>%
#  select(GEOID, foreign_born_pct) %>%
#  rename(ZCTA = GEOID)

# mean(is.na(census_foreign$foreign_born_pct))
```

```{r}
# prep for joining
social_capital$fips_n <-
  formatC(social_capital$fips_n, width = 5, format = "d", flag = "0")

names(social_capital)[1] <- "FIPS"

#
# cnts_counts <- select(org_activities_mbf, ZCTA, opp_mean) %>%
#  left_join(zcta_fips %>% select(ZCTA, FIPS)) %>%
#  select(-ZCTA) %>%
#  filter(!is.na(FIPS)) %>%
#  group_by(FIPS) %>%
#  summarize(n = n(),
#            mean_sum = sum(opp_mean))

# This does three things
# 1. It filters out organizations that only have a PO Box. Those are true organizations but perhaps not true geolocations
# 2. It combines organizations have have the same IRS group value in the same geography
# 3. It uses the FIPS derived from the latitude and longitude

cnts_counts <- org_activities_mbf %>%
  left_join(zcta_fips %>% select(ZCTA, FIPS)) %>%
  select(-ZCTA) %>%
  # rename(FIPS = fips) %>%
  group_by(FIPS, grouping_value) %>%
  summarise(m = max(opp_mean, na.rm = T)) %>%
  group_by(FIPS) %>%
  summarise(
    n = n(),
    mean_sum = sum(m)
  )
```

```{r}
# join the tables
dd <- cnts_counts %>%
  left_join(fips) %>%
  left_join(fips_census_agg) %>%
  left_join(social_capital) %>%
  left_join(county_class)
```

```{r}
# create the normalized index
dd <- dd %>%
  filter(!is.na(population_total)) %>%
  mutate(opc = 1000 * mean_sum / population_total) %>%
  mutate(
    opc_tile = ntile(opc, 5),
    opc_rank = percent_rank(opc),
    opc_cume_dist = cume_dist(opc)
  ) %>%
  mutate(all_org = 1000 * n / population_total)
```

```{r}
dd_sd <- dd %>%
  group_by(State) %>%
  summarize(
    mean = mean(opc_tile),
    median = median(opc_tile),
    sd = sd(opc_tile)
  ) %>%
  arrange(desc(mean))

dd_sd %>%
  DT::datatable()
```

```{r}
map_trade_off <- left_join(
  dd %>%
    group_by(State) %>%
    mutate(higher_cnts = opc_tile > 4) %>%
    summarize(pct_higher_cnts = mean(higher_cnts)),
  dd %>%
    group_by(State) %>%
    mutate(lower_cnts = opc_tile < 2) %>%
    summarize(pct_lower_cnts = mean(lower_cnts))
)
```

```{r}
map_trade_off %>%
  filter(State != "DC") %>%
  ggplot(aes(x = pct_lower_cnts, y = pct_higher_cnts, label = State)) +
  geom_text_repel() +
  coord_flip() +
  labs(
    x = "% of 1 graded counties",
    y = "% of 5 graded counties"
  ) +
  scale_x_continuous(label = scales::percent) +
  scale_y_continuous(label = scales::percent) +
  geom_vline(xintercept = 0.5, linetype = 2) +
  geom_hline(yintercept = 0.5, linetype = 2)

ggsave(here("outputs", "map_trade_off.png"), height = 6, width = 6)
```

# Discriminant validity test

```{r}
disc_plot <- dd %>%
  select(opc_tile, all_org, bonding, linking, bridging, socialcap) %>%
  rename(
    "Organizational density" = all_org,
    "Bonding" = bonding,
    "Linking" = linking,
    "Bridging" = bridging,
    "Social Capital" = socialcap
  ) %>%
  correlate() %>%
  shave() %>%
  select(c(1:2)) %>%
  slice(-1) %>%
  ggplot(aes(x = fct_reorder(term, opc_tile), y = opc_tile, label = round(opc_tile, 2))) +
  geom_col() +
  coord_flip() +
  labs(
    x = "",
    y = "Correlation coefficient \n with civic opportunity index"
  ) +
  geom_label(
    col = "black",
    show.legend = FALSE
  ) +
  ylim(c(0, 1))
```

```{r}
disc_table <- dd %>%
  select(opc_tile, all_org, bonding, linking, bridging, socialcap) %>%
  rename(
    "Organizational density" = all_org,
    "Bonding" = bonding,
    "Linking" = linking,
    "Bridging" = bridging,
    "Social Capital" = socialcap
  ) %>%
  correlate() %>%
  shave() %>%
  select(c(1:2)) %>%
  slice(-1) %>%
  arrange(desc(opc_tile)) %>%
  rename(
    "Measures" = term,
    "Corrleation coefficient" = opc_tile
  ) %>%
  gt()

gtsave(disc_table, here("outputs", "disc_table.docx"))
```

# Predictive validity 

```{r}
corr_mod <- dd %>%
  # group_by(State) %>%
  do(tidy(standardize(lm_robust(formula = opc_tile ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .)))) # Here standardize refers to refitting the model with standardized data (https://cran.r-project.org/web/packages/effectsize/vignettes/effectsize.html) z-scoring

corr_mod_rank <- dd %>%
  # group_by(State) %>%
  do(tidy(standardize(lm_robust(formula = opc_rank ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .)))) # Here standardize refers to refitting the model with standardized data (https://cran.r-project.org/web/packages/effectsize/vignettes/effectsize.html) z-scoring

corr_mod_cume_dist <- dd %>%
  # group_by(State) %>%
  do(tidy(standardize(lm_robust(formula = opc_cume_dist ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .)))) # Here standardize refers to refitting the model with standardized data (https://cran.r-project.org/web/packages/effectsize/vignettes/effectsize.html) z-scoring

corr_mod_rc <- dd %>%
  # group_by(State) %>%
  do(tidy(standardize(lm_robust(formula = all_org ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .))))
```

```{r}
corr_mod_bind <- bind_rows(
  mutate(corr_mod, DV = "Civic opportunity index"),
  mutate(corr_mod_rc, DV = "Organizational density")
)

pred_plot <- corr_mod_bind %>%
  mutate(term = recode(term,
    "race_per_white_nonhispanic" = "Non-hispanic white",
    "per_poverty" = "Federal poverty level",
    "college_educ" = "College educated"
  )) %>%
  filter(!str_detect(term, "(Intercept)")) %>%
  ggplot(aes(x = term)) +
  geom_text_repel(aes(y = estimate, label = round(estimate, 2), fill = DV, size = 1.5),
    position = position_dodge(width = 0.9),
    col = "black",
    show.legend = FALSE
  ) +
  geom_col(aes(y = estimate, fill = DV), position = "dodge", alpha = 0.4) +
  geom_errorbar(aes(ymax = estimate + std.error, ymin = estimate - std.error, fill = DV), position = "dodge", alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed", col = "red") +
  labs(
    x = "",
    y = "Estimated regression coefficient",
    fill = "Predictors"
  ) +
  scale_fill_viridis_d(begin = 0.1, end = 0.9) +
  # facet_wrap(~term, ncol = 2) +
  guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
  coord_flip() +
  theme(legend.position = "bottom")

pred_plot

ggsave(here("outputs", "pred_plot.png"), height = 6, width = 6)
```

# Create a map

## Join and shape 

```{r}
# Base map
sj <- tigris::counties(cb = TRUE) %>%
  mutate(id = row_number())

sj <- sj %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) # Sorry Alaska, Hawaii, and US Territories

write_rds(sj, here("processed_data", "sj.rds"))

sj_state <- tigris::states(cb = TRUE) %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) # Sorry Alaska, Hawaii, and US Territories
```

```{r}
sj <- read_rds(here("processed_data", "sj.rds"))
```

```{r}
tmp <- dd %>%
  select(FIPS, opc_tile) %>%
  left_join(org_activities_combined %>%
    rename(FIPS = fips) %>%
    select(FIPS, lat, lng)) %>%
  filter(!is.na(lng)) %>%
  st_as_sf(coords = c("lng", "lat"), crs = st_crs(sj), agr = "constant")
```

```{r}
combined_map <- sj %>% st_join(tmp)

write_rds(combined_map, here("processed_data", "combined_map.rds"))
```

```{r}
combined_map <- read_rds(here("processed_data", "combined_map.rds"))

combined_unique <- combined_map[!duplicated(combined_map$id), ] # 3,108 counties

write_rds(combined_unique, here("processed_data", "combined_unique.rds"))
```

```{r}
combined_unique <- read_rds(here("processed_data", "combined_unique.rds"))
```

```{r}
# Define the color palette
my_palette <- RColorBrewer::brewer.pal(5, "Greens")

# Create the map
us_county_map <- tm_shape(sj_state) +
  tm_borders() +
  tm_fill(col = "white") +
  tm_shape(sj) +
  tm_borders() +
  tm_shape(combined_unique) +
  tm_polygons(
    col = "opc_tile",
    palette = my_palette,
    midpoint = 3,
    colorNA = "grey50",
    title = "Civic opportunity index"
  ) +
  tm_layout(
    legend.position = c("left", "bottom")
  )

# View the map
us_county_map
```

```{r}
# Save the static map
tmap_save(us_county_map, file = here("outputs", "us_county_map.png"))
```
