---
title: "Civic opportunity measurement"
author: "Jae Yeon Kim"
date: "`r Sys.Date()`"
output: html_document
---

# Import pkgs 

```{r}
if (!require(pacman)) install.packages("pacman")

pacman::p_load(
  tidyverse,
  glue,
  here,
  purrr,
  estimatr,
  effectsize,
  ggrepel,
  patchwork,
  corrplot,
  corrr,
  tidycensus,
  callr,
  vroom,
  naniar,
  modelsummary
  #ltm # point-biserial correlation
)

devtools::install_github("graemeblair/stdidx")
library(stdidx)

options(es.use_symbols = TRUE) # get nice symbols

custom_theme <- function(size = 13) {
  theme_bw(base_size = size) +
    theme(
      aspect.ratio = 1.2,
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      axis.text.x = element_text(margin = margin(t = 6)),
      plot.title = element_text(size = 12),
      plot.subtitle = element_text(size = 10),
      plot.caption = element_text(colour = "grey50", hjust = 0),
      legend.position = "bottom"
    )
}

ggplot2::theme_set(custom_theme())
```

# Import data (from local sources)

```{r}
# this is the main data 
mbf <- vroom(here("raw_data", "irs_mbf.csv"))

# org activities from the websites and elsewhere 
org_activites <- vroom(here("raw_data", "irs_org_activities.csv"))

# fips (county-level)
fips <- read_csv(here("raw_data", "fips_with_population.csv"), col_types = (ZCTA <- "c"))

fips_cnts_invcov <- read_csv(here("raw_data", "fips_cnts_invcov.csv"))

fips_census_agg <- read_csv(here("raw_data", "census_fips_aggregate.csv"))

# social capital data 
social_capital <- read_csv(here("raw_data", "social_capital.csv"))
```

```{r}
# other demographic data 
census_detail <- read_csv(here("raw_data", "census_zcta_detail_data.csv"), col_types = (GEOID <- "c"))

zcta_fips <- read_csv(here("raw_data", "zcta_cnts.csv"))

census_subject <- read_csv(here("raw_data", "census_zcta_subject_data.csv"), col_types = (GEOID <- "c"))

county_class <- read_csv(here("raw_data", "County_Classifications.csv"))

#county_mutual <- read_csv(here("raw_data", "reproduction_data_mutual_aid_hubs_county.csv"))

names(county_class)[1] <- "FIPS"
```

# Create a sampling frame

- The old definition: An organization is considered a civic opportunity organization if it offers any of the following: volunteer opportunities, membership, ways to take civic or political action, or community events.

- The new definition: It follows the basic structure laid out in the old definition but places more weight on new information. For instance, most civic organizations provide membership (less weight), but only a few offer opportunities to take action (more weight).

```{r}
org_activites_mbf <- org_activites %>% 
  left_join(mbf %>% dplyr::select(ein, state, city, zip))

# Assumption: if any of the following variable has a non-NA value, the data come the organizations' websites. 

org_activites_mbf <- org_activites_mbf %>%
  mutate(website = ifelse(!is.na(take_action) | !is.na(volunteer) | !is.na(membership) | !is.na(events) | !is.na(resources) | !is.na(advocacy) | !is.na(services) | !is.na(chapters) | !is.na(board) | !is.na(press) | !is.na(donations), 1, 0)) %>%
  dplyr::select(ein, state, city, zip, take_action, volunteer, membership, events, website) %>%
  dplyr::distinct(ein, state, city, zip, take_action, volunteer, membership, events, website)
```

```{r}
subset(org_activites_mbf, take_action == 1)
```

```{r}
org_activites_mbf$website %>% sum() # 844,892

org_activites_mbf <- org_activites_mbf %>% 
  filter(website == 1) 

# Milan, I learned from you that this assumption is incorrect. Some of the activity values were detected through the IRS, rather than through the organizations' website data. Please make the necessary correction.

nrow(org_activites_mbf)

org_activites_mbf <- org_activites_mbf %>%
  replace_na(list(take_action = 0, volunteer = 0, membership = 0, events = 0))

# the first 5 digits
org_activites_mbf$ZCTA <- substr(org_activites_mbf$zip, 1, 5)
```

# Construct validity test at the org level

* The following three measures are on a 0-1 scale. 

* The objective of this exercise is to test the construct validity. This refers to the extent to which the instrument measures what it claims to measure in theory.

```{r}
org_activites_mbf <- org_activites_mbf %>%
  mutate(opp_binary = ifelse(volunteer == 1 | membership == 1 | take_action == 1 | events == 1, 1, 0)) %>% 
  mutate(
    opp_mean = idx_mean(volunteer, membership, take_action, events), # mean
    opp_invcov = idx_invcov(volunteer, membership, take_action, events) # inverse covariance matrix
  ) 

prin_out <- princomp(~volunteer + membership + take_action + events, data = org_activites_mbf)

org_activites_mbf$opp_princomp <- prin_out$scores[,1] # the first factor 

write_csv(org_activites_mbf, here("processed_data", "org_measures.csv"))
```

```{r}
unit_cor_df <- org_activites_mbf %>%
  dplyr::select(take_action, volunteer, membership, events, opp_binary, opp_mean, opp_invcov, opp_princomp) %>%
  rename("Taking action" = take_action,
         "Volunteering" = volunteer, 
         "Membership" = membership, 
         "Holding events" = events, 
         "Binary index" = opp_binary, 
         "Mean index" = opp_mean, 
         "Inverse covariance matrix index" = opp_invcov, 
         "Principal component first factor index" = opp_princomp) %>%
  correlate() %>%
  focus(c("Binary index",
         "Mean index", 
         "Inverse covariance matrix index", 
         "Principal component first factor index"))

sd(unit_cor_df[,2] %>% unlist) # sd binary index   
sd(unit_cor_df[,3] %>% unlist) # sd mean index 
sd(unit_cor_df[,4] %>% unlist) # sd inverse covariance matrix index 
sd(unit_cor_df[,5] %>% unlist) # sd principal component first factor index
```

```{r}
con_plot <- unit_cor_df %>%
  pivot_longer(matches("index")) %>%
  ggplot(aes(x = name, y = value, 
             fill = term,
             label = round(value, 2))) +
  geom_col(position = "dodge") +
  labs(x = "",
       y = "Correlaton coefficient",
       fill = "Dimensions",
       label = "Dimensions") +
  scale_fill_viridis_d(begin = 0.2, end = 0.6) +
  guides(fill = guide_legend(nrow = 2, 
                             byrow = TRUE)) +
  geom_label(position = position_dodge(width = 0.9),
             col = "white",
             show.legend = FALSE) +
  coord_flip() +
  ylim(c(0,1)) +
  theme(legend.position = "right")

con_plot 
```

# Link org and census data at the county level

```{r}
# county classification
county_class <- county_class %>%
  mutate(urban_suburban_rural = case_when(
    RuralUrbanContinuumCode2013 %in% c(1, 2, 3) ~ "Urban",
    RuralUrbanContinuumCode2013 %in% c(4, 5, 6) ~ "Suburban",
    RuralUrbanContinuumCode2013 %in% c(7, 8, 9) ~ "Rural",
    is.na(RuralUrbanContinuumCode2013) ~ NA
  )) %>%
  mutate(urban_suburban_rural = factor(urban_suburban_rural, levels = c("Urban", "Suburban", "Rural", NA)))
```

```{r}
# census_api_key(key = "69df6af664132347b84276a365ce76d4c16cf336")

# var20 <- load_variables(2020, "acs5", cache = TRUE)

# get_acs_zcta <- function(zcta_vec) {
#   census_api_data <- get_acs(
#     geography = "zcta",
#     variables = c(
#       "B05002_001", # total #
#       "B05002_013"
#     ), # foreign born #
#     geometry = FALSE,
#     output = "wide",
#     zcta = zcta_vec,
#     year = 2020
#   )
# }

# census_api_data <- map_dfr(census$ZCTA, get_acs_zcta)

# write_csv(census_api_data, here("raw_data", "census_api_data.csv"))

# census_api_data <- read_csv(here("raw_data", "census_api_data.csv"))

# census_foreign <- census_api_data %>%
# mutate(foreign_born_pct = B05002_013E / B05002_001E) %>%
#  select(GEOID, foreign_born_pct) %>%
#  rename(ZCTA = GEOID)

# mean(is.na(census_foreign$foreign_born_pct))
```

```{r}
# prep for joining 
names(fips_cnts_invcov)[1] <- "FIPS"

social_capital$fips_n <- 
  formatC(social_capital$fips_n, width = 5, format = "d", flag = "0")

names(social_capital)[1] <- "FIPS"

cnts_counts <- select(org_activites_mbf, ZCTA, opp_mean) %>%
  left_join(zcta_fips %>% select(ZCTA, FIPS)) %>%
  select(-ZCTA) %>%
  filter(!is.na(FIPS)) %>%
  group_by(FIPS) %>%
  summarize(n = n(),
            mean_sum = sum(opp_mean))

head(cnts_counts)
```

```{r}
cnts_counts %>%
  ggplot(aes(x = n, y = mean_sum)) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10()
```

```{r}
# join the tables 
dd <- cnts_counts %>%
  left_join(fips) %>%
  left_join(fips_census_agg) %>%
  left_join(social_capital) %>%
  left_join(county_class) 

# create the normalized index 

dd <- dd %>%
  filter(!is.na(population_total)) %>%
  mutate(opc = 1000 * mean_sum / population_total) %>%
  mutate(opc_tile = ntile(opc, 5)) %>%
  mutate(all_org = 1000 * n / population_total)
```

# Discriminant validity test

```{r}
disc_plot <- dd %>%
  select(opc_tile, all_org, bonding, linking, bridging, socialcap) %>%
  rename("Organizational density" = all_org,
         "Bonding" = bonding, 
         "Linking" = linking, 
         "Bridging" = bridging, 
         "Social Capital" = socialcap) %>%
  correlate() %>%
  shave() %>%
  select(c(1:2)) %>%
  slice(-1) %>%
  ggplot(aes(x = term, y = opc_tile, label = round(opc_tile, 2))) +
  geom_col() +
  coord_flip() +
  labs(x = "",
       y = "Correlation coefficient \n with civic opportunity index") +
  geom_label(col = "black",
             show.legend = FALSE) +
  ylim(c(0,1))
```

# Predictive validity 

```{r}
head(dd)
```

```{r}
corr_mod <- dd %>%
  #group_by(urban_suburban_rural) %>%
  do(tidy(standardize(lm_robust(formula = opc_tile ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .))))

corr_mod_rc <- dd %>%
  #group_by(urban_suburban_rural) %>%
  do(tidy(standardize(lm_robust(formula = all_org ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .))))

corr_mod_bind <- bind_rows(
  mutate(corr_mod, DV = "Civic opportunity index"),
  mutate(corr_mod_rc, DV = "Organizational density")
)
```

```{r}
pred_plot <- corr_mod_bind %>%
  mutate(term = recode(term,
    "race_per_white_nonhispanic" = "Non-hispanic white",
    "per_poverty" = "Federal poverty level",
    "college_educ" = "College educated"
  )) %>%
  filter(!str_detect(term, "(Intercept)")) %>%
  ggplot(aes(x = term)) +
  geom_text_repel(aes(y = estimate, label = round(estimate, 2), fill = DV, size = 1.5), 
             position = position_dodge(width = 0.9),
             col = "black",
             show.legend = FALSE) +
  geom_col(aes(y = estimate, fill = DV), position = "dodge", alpha = 0.5) +
  geom_errorbar(aes(ymax = estimate + std.error, ymin = estimate - std.error, fill = DV), position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", col = "red") +
  labs(
    x = "",
    y = "Estimated coefficient",
    fill = "Predictors"
  ) +
  scale_fill_viridis_d(begin = 0.2, end = 0.6) +
  #facet_wrap(~term, ncol = 2) +
  guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
  coord_flip() +
  theme(legend.position = "right")
```

# Put them all

```{r}
con_plot / disc_plot / pred_plot +  plot_annotation(tag_level = "A")

ggsave(here("outputs", "measurement_validation.png"), height = 10, 
       width = 10)
```