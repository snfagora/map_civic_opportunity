---
title: "Data wrangling"
author: "Jae Yeon Kim"
date: "`r Sys.Date()`"
output: html_document
---

# Import pkgs 

```{r}
if (!require(pacman)) install.packages("pacman")

pacman::p_load(
  broom, 
  tidyverse,
  glue,
  here,
  purrr,
  estimatr,
  effectsize,
  sandwich,
  ggrepel,
  patchwork,
  ggpubr, 
  corrplot,
  corrr,
  tidycensus,
  callr,
  vroom,
  naniar,
  modelsummary,
  gt,
  DT,
  sf,
  tigris,
  tmap,
  RColorBrewer,
  usdata
)

library("tidylog", warn.conflicts = FALSE)

devtools::install_github("graemeblair/stdidx")
library(stdidx)

options(es.use_symbols = TRUE) # get nice symbols

custom_theme <- function(size = 13) {
  theme_bw(base_size = size) +
    theme(
      aspect.ratio = 1.2,
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      axis.text.x = element_text(margin = margin(t = 6)),
      plot.title = element_text(size = 12),
      plot.subtitle = element_text(size = 10),
      plot.caption = element_text(colour = "grey50", hjust = 0),
      legend.position = "bottom"
    )
}

ggplot2::theme_set(custom_theme())
```

# Import data 

```{r}
# MMA data 
## master file 
mbf <- vroom(here("raw_data", "irs_mbf.csv"))

## org activities from the websites and elsewhere 
org_activities <- vroom(here("raw_data", "irs_org_activities.csv"))

irs_activities <- vroom(here("raw_data","irs_nonweb_activities.csv"))

irs_activities <- irs_activities %>%
  replace_na(list(volunteer_text = 0, member_text = 0)) # without this, the following mutate won't work

## PO BOX status
po_status <- read_csv(here("raw_data", "irs_po_status.csv"))

## orgs geolocated to FIPS
irs_to_fips <- vroom(here("raw_data", "irs_to_fips.csv"))

# Census data 

## County level 
fips <- read_csv(here("raw_data", "fips_with_population.csv"), col_types = (ZCTA <- "c"))

fips_census_agg <- read_csv(here("raw_data", "census_fips_aggregate.csv"))

county_class <- read_csv(here("raw_data", "County_Classifications.csv"))

# ZCTA-level demographic data

## other demographic data
zcta_detail <- read_csv(here("raw_data", "census_zcta_detail_data.csv"), col_types = (GEOID <- "c"))

names(county_class)[1] <- "FIPS"

# Other data (social capital)

## Kyne and Aldrich
ka_sc <- read_csv(here("raw_data", "ka_social_capital.csv"))

## Penn State Index
penn_sc <- read_csv(here("raw_data", "penn_state_social_capital.csv")) %>%
  mutate(FIPS = ifelse(str_length(FIPS) < 5, paste0("0", FIPS), FIPS))

## Chetty et al index
chetty_sc <- read_csv(here("raw_data", "chetty_et_al_social_capital.csv")) %>%
  mutate(county = ifelse(str_length(county) < 5, paste0("0", county), county)) %>%
  rename(FIPS = county)

# Spatial data 

zcta_cnts <- read_csv(here("processed_data", "zcta_counts_idx_mean_nonpo.csv"))

la_zip_df <- read_csv(here("raw_data", "zipcode_la.csv"))

la_zip_shp <- read_sf(here("raw_data", "Zip_Codes_(LA_County).shp"))
```

# Create a sampling frame

```{r}
org_activities_combined <- irs_activities %>%
  left_join(org_activities) %>%
  mutate(
    volunteer = ifelse(volunteer_text == 1, 1, volunteer),
    membership = ifelse(member_text == 1, 1, membership)
  )
```

```{r}
org_activities_mbf <- org_activities_combined %>%
  left_join(mbf %>% dplyr::select(ein, state, city, zip, irs_group)) %>%
  mutate(grouping_value = if_else(irs_group != "0000", irs_group, ein)) %>%
  left_join(po_status) %>%
  left_join(irs_to_fips)

nrow(org_activities_mbf) # 1,774,798, approximately 1.8M orgs this is the sampling frame
```

```{r}
org_activities_mbf <- org_activities_mbf %>%
  mutate(extractable = ifelse(!is.na(take_action) | !is.na(volunteer) | !is.na(membership) | !is.na(events) | !is.na(resources) | !is.na(advocacy) | !is.na(services) | !is.na(chapters) | !is.na(board) | !is.na(press) | !is.na(donations), 1, 0)) %>%
  dplyr::select(ein, state, city, zip, take_action, volunteer, membership, events, extractable, grouping_value, is_po, fips)
```

```{r}
org_activities_mbf$extractable %>% sum() # 894,888

org_activities_mbf$extractable %>% sum() / nrow(org_activities_mbf)

org_activities_mbf <- org_activities_mbf %>%
  # filter(extractable == 1) %>% # this includes both websites and IRS
  filter(is_po != 1) # PO BOX

nrow(org_activities_mbf) # 1,363,701

org_activities_mbf <- org_activities_mbf %>%
  replace_na(list(take_action = 0, volunteer = 0, membership = 0, events = 0))

# the first 5 digits
org_activities_mbf$ZCTA <- substr(org_activities_mbf$zip, 1, 5)

(org_activities_mbf %>%
  filter(take_action != 0 | volunteer != 0 | membership != 0 | events != 0) %>%
  nrow()) / nrow(org_activities_combined) # 32%
```

```{r}
nonweb_eins <- irs_activities %>%
  rename(
    volunteer = volunteer_text,
    membership = member_text
  ) %>%
  select(ein, volunteer, membership) %>%
  # replace_na(list(volunteer = 0, membership = 0)) %>%
  filter(volunteer == 1 | membership == 1) %>%
  pull(ein)

org_activities_mbf$nonweb <- org_activities_mbf$ein %in% nonweb_eins

org_activities_mbf %>%
  mutate(web = ifelse(nonweb == FALSE | nonweb == TRUE & take_action == 1 | nonweb == TRUE & events == 1, TRUE, FALSE)) %>%
  mutate(status = as.numeric(nonweb) + as.numeric(web)) %>%
  mutate(status = ifelse(status == 2, "Both",
    ifelse(status == 1 & web == TRUE, "Web",
      ifelse(status == 1 & nonweb == TRUE, "IRS", NA)
    )
  )) %>%
  group_by(status) %>%
  summarize(n = n()) %>%
  mutate(freq = n / sum(n))
```

# Construct validity test at the org level

* The following three measures are on a 0-1 scale. 

* The objective of this exercise is to test the construct validity. This refers to the extent to which the instrument measures what it claims to measure in theory.

```{r}
org_activities_mbf <- org_activities_mbf %>%
  mutate(opp_binary = ifelse(volunteer == 1 | membership == 1 | take_action == 1 | events == 1, 1, 0)) %>%
  mutate(
    opp_mean = idx_mean(volunteer, membership, take_action, events), # mean
    opp_invcov = idx_invcov(volunteer, membership, take_action, events) # inverse covariance matrix
  )

prin_out <- princomp(~ volunteer + membership + take_action + events, data = org_activities_mbf)

org_activities_mbf$opp_princomp <- prin_out$scores[, 1] # the first factor

write_csv(org_activities_mbf, here("processed_data", "org_measures.csv"))

civic_orgs <- org_activities_mbf %>%
  filter(opp_mean > 0)

write_csv(civic_orgs, here("processed_data", "civic_orgs.csv"))
```

```{r}
unit_cor_df <- org_activities_mbf %>%
  dplyr::select(take_action, volunteer, membership, events, opp_binary, opp_mean, opp_invcov, opp_princomp) %>%
  rename(
    "Taking action" = take_action,
    "Volunteering" = volunteer,
    "Membership" = membership,
    "Holding events" = events,
    "Binary index" = opp_binary,
    "Mean index" = opp_mean,
    "Inverse covariance matrix index" = opp_invcov,
    "Principal component first factor index" = opp_princomp
  ) %>%
  correlate() %>%
  focus(c(
    "Binary index",
    "Mean index",
    "Inverse covariance matrix index",
    "Principal component first factor index"
  ))

# for publication 
write_csv(unit_cor_df, here("data_outputs", "unit_cor_df.csv"))
```

# Link org and census data at the county level

```{r}
# county classification
county_class <- county_class %>%
  mutate(urban_suburban_rural = case_when(
    RuralUrbanContinuumCode2013 %in% c(1, 2, 3) ~ "Urban",
    RuralUrbanContinuumCode2013 %in% c(4, 5, 6) ~ "Suburban",
    RuralUrbanContinuumCode2013 %in% c(7, 8, 9) ~ "Rural",
    is.na(RuralUrbanContinuumCode2013) ~ NA
  )) %>%
  mutate(urban_suburban_rural = factor(urban_suburban_rural, levels = c("Urban", "Suburban", "Rural", NA)))
```

```{r}
# prep for joining
ka_sc$fips_n <-
  formatC(ka_sc$fips_n, width = 5, format = "d", flag = "0")

names(ka_sc)[1] <- "FIPS"

#
# cnts_counts <- select(org_activities_mbf, ZCTA, opp_mean) %>%
#  left_join(zcta_fips %>% select(ZCTA, FIPS)) %>%
#  select(-ZCTA) %>%
#  filter(!is.na(FIPS)) %>%
#  group_by(FIPS) %>%
#  summarize(n = n(),
#            mean_sum = sum(opp_mean))

# This does three things
# 1. It filters out organizations that only have a PO Box. Those are true organizations but perhaps not true geolocations
# 2. It combines organizations have have the same IRS group value in the same geography
# 3. It uses the FIPS derived from the latitude and longitude
```

```{r}
cnts_counts <- org_activities_mbf %>%
  # left_join(zcta_fips %>% select(ZCTA, FIPS)) %>%
  # select(-ZCTA) %>%
  rename(FIPS = fips) %>%
  group_by(FIPS, grouping_value) %>%
  summarise(m = max(opp_mean, na.rm = T)) %>%
  group_by(FIPS) %>%
  summarise(
    n = n(),
    mean_sum = sum(m)
  )
```

```{r}
# join the tables
dd <- cnts_counts %>%
  left_join(fips) %>%
  left_join(fips_census_agg) %>%
  # Kyne and Aldrich 
  left_join(ka_sc) %>%
  left_join(county_class)
```

```{r}
# create the normalized index
dd <- dd %>%
  filter(!is.na(population_total)) %>%
  mutate(opc = 1000 * mean_sum / population_total) %>%
  mutate(
    opc_tile = ntile(opc, 5),
    opc_rank = percent_rank(opc),
    opc_cume_dist = cume_dist(opc)
  ) %>%
  mutate(
    all_org = 1000 * n / population_total,
    all_org_tile = ntile(all_org, 5)
  )
```

```{r}
dd_sd <- dd %>%
  group_by(State) %>%
  summarize(
    mean = mean(opc_tile),
    median = median(opc_tile),
    sd = sd(opc_tile)
  ) %>%
  arrange(desc(mean))

dd_sd %>%
  DT::datatable()
```

```{r}
map_trade_off <- left_join(
  dd %>%
    group_by(State) %>%
    mutate(higher_cnts = opc_tile >= 4) %>%
    summarize(pct_higher_cnts = mean(higher_cnts)),
  dd %>%
    group_by(State) %>%
    mutate(lower_cnts = opc_tile <= 2) %>%
    summarize(pct_lower_cnts = mean(lower_cnts))
)

map_trade_off %>%
  DT::datatable()

# for publications
write_csv(map_trade_off, here("data_outputs", "map_trade_off.csv"))
```

# Discriminant validity test

```{r}
disc_table <- dd %>%
  select(opc_tile, all_org, bonding, linking, bridging, socialcap) %>%
  rename(
    "Organizational density" = all_org,
    "Social Capital" = socialcap,
    "Bonding" = bonding,
    "Bridging" = bridging,
    "Linking" = linking
  ) %>%
  correlate() %>%
  shave() %>%
  select(c(1:2)) %>%
  slice(-1) %>%
  rename(
    "Measures" = term,
    "Correlation coefficient" = opc_tile
  ) %>%
  mutate(Measures = fct_relevel(Measures, c("Organizational density", "Social Capital", "Bonding", "Bridging", "Linking"))) %>%
  arrange(Measures) %>%
  gt()

disc_table

gtsave(disc_table, here("outputs", "disc_table.docx"))
```


```{r}
dd <- dd %>% 
  # join with the Penn State social capital data
  left_join(penn_sc, by = c("FIPS" = "FIPS")) %>%
  # join with the Chetty et al index 
  left_join(chetty_sc)

mma_sc_demo <- dd %>%
  select(FIPS, opc, socialcap, sk2014, civic_organizations_county, race_per_white_nonhispanic, per_poverty, college_educ)

# For publication
write_csv(mma_sc_demo, here("data_outputs", "mma_sc_demo.csv"))
```

# Predictive validity 

```{r}
corr_mod <- dd %>%
  # group_by(State) %>%
  do(tidy(standardize(lm_robust(formula = opc ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .)))) # Here standardize refers to refitting the model with standardized data (https://cran.r-project.org/web/packages/effectsize/vignettes/effectsize.html) z-scoring

corr_mod_rc <- dd %>%
  # group_by(State) %>%
  do(tidy(standardize(lm_robust(formula = all_org ~ race_per_white_nonhispanic + per_poverty + college_educ, data = .))))
```

```{r}
corr_mod_bind <- bind_rows(
  mutate(corr_mod, DV = "Civic opportunity index"),
  mutate(corr_mod_rc, DV = "Organizational density")
)

pred_plot <- corr_mod_bind %>%
  mutate(term = recode(term,
    "race_per_white_nonhispanic" = "Non-hispanic white",
    "per_poverty" = "Federal poverty level",
    "college_educ" = "College educated"
  )) %>%
  filter(!str_detect(term, "(Intercept)")) %>%
  ggplot(aes(x = term)) +
  geom_text_repel(aes(y = estimate, label = round(estimate, 2), fill = DV, size = 1.5),
    position = position_dodge(width = 0.9),
    col = "black",
    show.legend = FALSE
  ) +
  geom_col(aes(y = estimate, fill = DV), position = "dodge", alpha = 0.4) +
  geom_errorbar(aes(ymax = estimate + std.error, ymin = estimate - std.error, fill = DV), position = "dodge", alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed", col = "red") +
  labs(
    x = "Predictors",
    y = "Estimated regression coefficient",
    fill = "Response variables"
  ) +
  scale_fill_viridis_d(begin = 0.1, end = 0.9) +
  # facet_wrap(~term, ncol = 2) +
  guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
  coord_flip() +
  theme(legend.position = "bottom")

pred_plot

ggsave(here("outputs", "pred_plot.png"), height = 6, width = 6)
```

# Civic opportunity and inequality

```{r}
mod_comp_list <- list(
  "Civic opportunity" = standardise(lm_robust(opc ~ per_poverty, data = dd)),
  "Social capital" = standardise(lm_robust(sk2014 ~ per_poverty, data = dd)),
  "Civic opportunity" = standardise(lm_robust(opc ~ college_educ, data = dd)),
  "Social capital" = standardise(lm_robust(sk2014 ~ college_educ, data = dd)),
  "Civic opportunity" = standardise(lm_robust(opc ~ race_per_white_nonhispanic, data = dd)),
  "Social capital" = standardise(lm_robust(sk2014 ~ race_per_white_nonhispanic, data = dd))
)
```

```{r}
modelsummary(mod_comp_list,
  fmt = 3,
  estimate = c("{estimate}"),
  statistic = c("conf.int",
                "s.e. = {std.error}", 
                "p = {p.value}"),
  coef_omit = "Intercept",
  coef_map =
    c(
      "race_per_white_nonhispanic" = "Non-hispanic white",
      "per_poverty" = "Federal poverty level",
      "college_educ" = "College educated"
    ),
  output = here("outputs", "reg_two_measures.docx")
)
```

# Create a map

```{r}
la_zipcodes <- la_zip_df$ZIP %>% as.character()

zcta_detail$ZCTA <- zcta_detail$GEOID

zcta_combined <- zcta_cnts %>%
  right_join(
    zcta_detail %>%
      select(ZCTA, population_total)
  ) %>%
  filter(!is.na(population_total)) %>%
  mutate(opc = 1000 * mean_sum / population_total) %>%
  mutate(
    opc_tile = ntile(opc, 5),
  )

la_zcta_cnts <- zcta_combined %>%
  filter(ZCTA %in% la_zipcodes)

# get LA shape file

la_zip_shp$ZCTA <- as.character(la_zip_shp$ZIP)

la_zcta_opc <- la_zcta_cnts %>%
  select(ZCTA, opc_tile)

# for publication
write_csv(la_zcta_opc, here("data_outputs", "la_zcta_opc.csv"))

la_map_cnts <- merge(la_zcta_cnts, la_zip_shp)

# Base map
sj <- tigris::counties(cb = TRUE) %>%
  mutate(id = row_number())

sj <- sj %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) # Sorry Alaska, Hawaii, and US Territories

write_rds(sj, here("processed_data", "sj.rds"))

sj_state <- tigris::states(cb = TRUE) %>%
  filter(!(STATEFP %in% c("02", "15", "60", "66", "69", "72", "78"))) # Sorry Alaska, Hawaii, and US Territories

write_rds(sj_state, here("processed_data", "sj_state.rds"))

sj <- read_rds(here("processed_data", "sj.rds"))
sj_state <- read_rds(here("processed_data", "sj_state.rds"))

tmp <- dd %>%
  select(FIPS, opc_tile) %>%
  left_join(org_activities_combined %>%
    rename(FIPS = fips) %>%
    select(FIPS, lat, lng)) %>%
  filter(!is.na(lng)) %>%
  st_as_sf(coords = c("lng", "lat"), crs = st_crs(sj), agr = "constant")

combined_map <- sj %>% st_join(tmp)

write_rds(combined_map, here("processed_data", "combined_map.rds"))

combined_map <- read_rds(here("processed_data", "combined_map.rds"))

combined_unique <- combined_map[!duplicated(combined_map$id), ] # 3,108 counties

write_rds(combined_unique, here("processed_data", "combined_unique.rds"))

# for publication
write_rds(combined_unique, here("data_outputs", "county_opc.rds"))

combined_unique <- read_rds(here("processed_data", "combined_unique.rds"))

# No islands
la_zip_shp <- la_zip_shp %>%
  filter(!(ZIPCODE %in% c("90704", "90731")))

la_map_cnts <- la_map_cnts %>%
  filter(!(ZCTA %in% c("90704", "90731")))

# for publication
st_write(la_zip_shp, here("data_outputs", "la_zip_shp.shp"))

la_map_cnts <- la_map_cnts %>%
  select(-c("n", "mean_sum", "population_total", "opc"))

# for publication
write_csv(la_map_cnts, here("data_outputs", "la_map_cnts.csv"))
```